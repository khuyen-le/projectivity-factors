---
title: "Find Predicates with Residuals Closest to 0"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
library(ggplot2)
library(jsonlite)
library(tidyr)
library(stringr)
library(dplyr)
library(ggthemes)
library(ggrepel)
library(dichromat)
library(lme4)
library(performance)
library(languageR)
library(gghighlight)
theme_set(theme_bw())
```

```{r}
vp_raw <- read.csv("../data/mega-veridicality-v2.csv")
emotion_raw <- read.csv("../data/BRM-emot-submit.csv")
emotion_select <- select(emotion_raw, "Word", "V.Mean.Sum", "V.SD.Sum", "A.Mean.Sum", "A.SD.Sum")
vp_data <- select(vp_raw, "participant", "verb", "frame", "voice", "polarity", "conditional", "sentence", "veridicality", "acceptability", "exclude")
```
#### Norming valence mean to get positive and negative valence
```{r}
emotion <- emotion_select %>%
  mutate(valence_scaled = scale(V.Mean.Sum))
word_list <- unique(emotion$Word)
```

```{r}
# Need to filter by acceptability (see 2019 paper)
# Need to normalize by participants (2016 paper used "ordinal model-based normalization procedure")
vp_data <- vp_data %>%
  mutate(veridicality_num = ifelse(veridicality == "yes", 1, ifelse(veridicality == "no", -1, 0))) %>%
  filter(exclude == "False") %>%
  mutate(Word = verb) %>%
  filter(Word %in% word_list)
```

#### create relevant subset for projectivity ratings
##### examples of items: 
```{r table_projectivity, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl_proj <- "
| Frame  | Voice  | Valence  | Sentence                                                                          | Note                                    |
|--------|:------:|:--------:|-----------------------------------------------------------------------------------| ----------------------------------------|
| that_S | active | positive | If John didn't find that a particular thing happened, did that thing happen?      | arousal low, projectivity low           |
| that_S | passive| negative | If John wasn't scared that a particular thing happened, did that thing happen?    | arousal high, projectivity high         |
| that_S | active | positive | If John didn't discover that a particular thing happened, did that thing happen?  | outlier: arousal high, projectivity low |
| that_S | passive| positive | If John wasn't jarred that a particular thing happened, did that thing happen?    | outlier: arousal low, projectivity high |
| that_S | active | negative | If John didn't resent that a particular thing happened, did that thing happen?    | outlier: arousal low, projectivity high |
| that_S | passive| negative | If John wasn't tricked that a particular thing happened, did that thing happen?   | outlier: arousal high, projectivity low |
"
cat(tabl_proj)
```

```{r, fig.width = 10, fig.height = 8}
projectivity_filter <- vp_data %>%
  filter(polarity == "negative" & conditional == "True") 
```

```{r explore acceptability}
projectivity_filter <- projectivity_filter %>%
  group_by(participant) %>%
  mutate(acceptability_norm = (acceptability - mean(acceptability)) / sd(acceptability))

# only take acceptability >= 0
projectivity_filter <- projectivity_filter %>%
  filter(acceptability_norm >= 0)
```

```{r merge with emotion}
projectivity_filter <- merge(projectivity_filter, emotion, by = "Word", all.x = TRUE) 
projectivity_filter <- projectivity_filter %>%
  rename(valence_mean = valence_scaled, arousal_mean = A.Mean.Sum, valence_SD = V.SD.Sum, arousal_SD = A.SD.Sum) %>%
  mutate(valence_group = ifelse(valence_mean < 0, "negative", "positive"))
```

#### Sort predicates according to valence
```{r}
projectivity_neg_participant <- projectivity_filter %>%
  filter(valence_group == "negative")

projectivity_neg_participant <-projectivity_neg_participant[order(projectivity_neg_participant$valence_mean),]
projectivity_neg_participant[c("valence_bin")] <- 0
sep_neg = nrow(projectivity_neg_participant) / 3
for (i in 1:nrow(projectivity_neg_participant)) {
  if (i <= sep_neg) {
    projectivity_neg_participant[i, "valence_bin"] <- "very negative"
  } else if (i <= 2 * sep_neg) {
    projectivity_neg_participant[i, "valence_bin"] <- "moderately negative"
  } else {
    projectivity_neg_participant[i, "valence_bin"] <- "slightly negative"
  }
}

projectivity_pos_participant <- projectivity_filter %>%
  filter(valence_group == "positive")

projectivity_pos_participant <-projectivity_pos_participant[order(projectivity_pos_participant$valence_mean),]
projectivity_pos_participant[c("valence_bin")] <- 0
sep_pos = nrow(projectivity_pos_participant) / 3
for (i in 1:nrow(projectivity_pos_participant)) {
  if (i <= sep_pos) {
    projectivity_pos_participant[i, "valence_bin"] <- "slightly positive"
  } else if (i <= 2 * sep_pos) {
    projectivity_pos_participant[i, "valence_bin"] <- "moderately positive"
  } else {
    projectivity_pos_participant[i, "valence_bin"] <- "very positive"
  }
}

projectivity_participant <- rbind(projectivity_neg_participant, projectivity_pos_participant)

# ggplot(data = projectivity_participant, aes(x = valence_mean, y = projectivity_mean, colour = valence_group, label = Word)) +
#   #geom_point(width = .3,height = .025) +
#   geom_label() +
#   geom_smooth(method = 'lm')
# 
# ggplot(data = projectivity_participant, aes(x = arousal_mean, y = projectivity_mean, colour = valence_group, label = Word)) +
#   #geom_point(width = .3,height = .025) + 
#   facet_grid(~valence_group) +
#   geom_label() +
#   geom_smooth(method = 'lm')
# 
# # taking into account voice
# ggplot(data = projectivity_participant, aes(x = arousal_mean, y = projectivity_mean, colour = valence_group, label = Word)) +
#   #geom_point(width = .3,height = .025) + 
#   facet_grid(voice~valence_group) +
#   geom_label() +rm 
#   geom_smooth(method = 'lm')
```

#### Sort predicates by arousal
```{r}
projectivity_participant <- projectivity_participant[order(projectivity_participant$arousal_mean),]
projectivity_participant[c("arousal_bin")] <- 0
sep = nrow(projectivity_participant) / 3
for (i in 1:nrow(projectivity_participant)) {
  if (i <= sep) {
    projectivity_participant[i, "arousal_bin"] <- "low"
  } else if (i <= 2 * sep_pos) {
    projectivity_participant[i, "arousal_bin"] <- "medium"
  } else {
    projectivity_participant[i, "arousal_bin"] <- "high"
  }
}

```

```{r plot projectivity by valence and arousal}
projectivity_summarize <- projectivity_participant %>%
  group_by(Word, valence_mean, valence_group, valence_bin, arousal_mean, arousal_bin) %>%
  summarise(projectivity_mean = mean(veridicality_num))
  
ggplot(data = projectivity_summarize, aes(x = arousal_mean, y = projectivity_mean, colour = arousal_bin, label = Word)) +
  #geom_point(width = .3,height = .025) +
  geom_label() +
  geom_smooth(method = 'lm')

ggplot(data = projectivity_summarize, aes(x = valence_mean, y = projectivity_mean,, colour = valence_bin, label = Word)) +
  #geom_point(width = .3,height = .025) +
  geom_label() +
  geom_smooth(method = 'lm')
```

```{r mixed effects linear model}
# visualize correlations between variables
#pairscor.fnc(projectivity_participant[,c("veridicality_num","arousal_mean","relativeValence","valence_mean")])

# the model check of the model as previously formulated (ie, with uncentered predictors) suggested huge collinearity, almost all values in covariance matrix > .4). the current model check still suggests there's sth wonky going on with the homoscedasticity tests (because the outcome variable is a three-way categorical variable instead of continuous, which we can't do anything about within the model, but see logistic model below that replicates the result). 
projectivity_participant$relativeValence = abs(projectivity_participant$valence_mean)
projectivity_participant = projectivity_participant %>%
  mutate(crelativeValence=relativeValence-mean(relativeValence),
        carousal_mean=arousal_mean-mean(arousal_mean))

m = lmer(veridicality_num ~ carousal_mean * crelativeValence + (1 | participant) + (1 | Word), data = projectivity_participant)
summary(m) # main effects of arousal and relative valence!
plot(fitted(m), residuals(m))

pdf(file="modelcheck_linear.pdf",height=8,width=9)
check_model(m)
dev.off()

factivity.full = lmer(veridicality_num ~ carousal_mean * crelativeValence + (1 | participant) + (1 | Word), data = projectivity_participant, REML = FALSE)
factivity.reduced = lmer(veridicality_num ~ 1 + (1 | participant) + (1 | Word), data = projectivity_participant, REML = FALSE)
anova(factivity.reduced, factivity.full)

```
#### Sort residuals
```{r}
### Residuals might be different within the same predicates because veridicality_num of each participant is different
### Thus, not using unique predicates (not sure if this is a problem)
projectivity_participant$residuals <- residuals(m)
projectivity_participant$residuals_abs <- abs(projectivity_participant$residuals)
projectivity_participant_summary <- projectivity_participant %>%
  group_by(Word, valence_group, valence_bin, arousal_bin, carousal_mean, crelativeValence) %>%
  summarize(mean_residuals_abs = mean(residuals_abs), mean_acceptability_norm = mean(acceptability_norm, na.rm = TRUE), projectivity_mean = mean(veridicality_num)) ## mean_acceptability_norm for display only
headprojectivity_participant_summary <- projectivity_participant_summary[order(projectivity_participant_summary$mean_residuals_abs),]

valence_highpos_arousal_high <- projectivity_participant_summary %>%
  filter((valence_bin == "very positive" | valence_bin == "moderately positive") & arousal_bin == "high")
valence_highpos_arousal_med <- projectivity_participant_summary %>%
  filter((valence_bin == "very positive" | valence_bin == "moderately positive") & arousal_bin == "medium")
valence_highpos_arousal_low <- projectivity_participant_summary %>%
  filter((valence_bin == "very positive" | valence_bin == "moderately positive") & arousal_bin == "low")
valence_highneg_arousal_high <- projectivity_participant_summary %>%
  filter((valence_bin == "very negative" | valence_bin == "moderately negative") & arousal_bin == "high")
valence_highneg_arousal_med <- projectivity_participant_summary %>%
  filter((valence_bin == "very negative" | valence_bin == "moderately negative") & arousal_bin == "medium")
valence_highneg_arousal_low <- projectivity_participant_summary %>%
  filter((valence_bin == "very negative" | valence_bin == "moderately negative") & arousal_bin == "low")
valence_low_arousal_high <- projectivity_participant_summary %>%
  filter((valence_bin == "slightly negative" | valence_bin == "slightly positive") & arousal_bin == "high")
valence_low_arousal_med <- projectivity_participant_summary %>%
  filter((valence_bin == "slightly negative" | valence_bin == "slightly positive") & arousal_bin == "medium")
valence_low_arousal_low <- projectivity_participant_summary %>%
  filter((valence_bin == "slightly negative" | valence_bin == "slightly positive") & arousal_bin == "low")

top_words <- rbind(valence_highpos_arousal_high[1:10, ], 
                   valence_highpos_arousal_med[1:10, ],
                   valence_highpos_arousal_low[1:10, ],
                   valence_highneg_arousal_high[1:10, ], 
                   valence_highneg_arousal_med[1:10, ], 
                   valence_highneg_arousal_low[1:10, ], 
                   valence_low_arousal_high[1:10, ],
                   valence_low_arousal_low[1:10, ],
                   valence_low_arousal_low[1:10, ])
top_words <- na.omit(top_words) # some categories have fewer than 10 words
write.csv(top_words, "top_words.csv")top
kable(top_words)
```

```{r, fig.width = 8, fig.height = 8}
label_words <- pull(top_words[c("Word")])

projectivity_participant_summary <- projectivity_participant_summary %>%
  mutate(word_flag = ifelse(Word %in% label_words, 1, 0))
  
ggplot(data = projectivity_participant_summary, aes(x = carousal_mean, y = projectivity_mean, label = Word)) +
  geom_point() +
  gghighlight(word_flag == 1, label_key = Word) +
  facet_grid(~valence_group) +
  geom_label_repel() +
  geom_smooth(method = 'lm')
```


```{r mixed effects logistic model}
# create a categorical projectivity variable that treats only "yes" responses as projective, all others as not projective
projectivity_participant$categorical_projectivity = as.factor(ifelse(projectivity_participant$veridicality_num == 1, "projective","non-projective"))

# almost three times as many non-projective compared to projective responses
table(projectivity_participant$categorical_projectivity)
prop.table(table(projectivity_participant$categorical_projectivity))

m = glmer(categorical_projectivity ~ carousal_mean * crelativeValence + (1 | participant) + (1 | Word), data = projectivity_participant, family="binomial")
summary(m) # main effects of arousal and relative valence!

```