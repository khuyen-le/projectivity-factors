---
title: "exp3_at-issue_analysis"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
library(ggplot2)
library(jsonlite)
library(tidyr)
library(stringr)
library(dplyr)
library(ggthemes)
library(ggrepel)
library(dichromat)
library(lme4)
library(performance)
library(languageR)
library(gghighlight)
theme_set(theme_bw())
library(brms)
library(rstan)
library(plot3D)
```

```{r import data}
top_words_selected <- read.csv("../../../explore/top_words_selected.csv")
top_words_selected <- select(top_words_selected, "Word", "voice", "valence_group", "valence_bin", "valence_bin_group", "arousal_bin", "valence_arousal_group", "carousal_mean", "crelativeValence", "valence_mean", "mean_residuals_abs","mean_acceptability_norm")
data_raw <- read.csv("../data/atissue_exp-trials.csv")
data_participants_raw <- read.csv("../data/atissue_exp-subject_information.csv")
```

# Native speakers
## We exclude any speakers who did not report English as a native language in the post-survey demographic questions.
```{r filter native English speakers, warning = FALSE}
# get participants whose native language is English
data_participants <- data_participants_raw %>%
  mutate(language = tolower(language))

nrow(data_participants_raw) #150


#filter out participants who did not report English as native language (n=6)
data_participants = filter(data_participants, grepl("eng", language))
nrow(data_participants) # 144

worker_id <- data_participants$workerid

data_select <- data_raw %>%
  filter(utterance != "bot_check") %>%
  filter(workerid %in% worker_id)

data_select <- data_select %>%
  mutate(response_num = as.numeric(response))
  #mutate(response_num = as.numeric(levels(response))[response])
```
# Control trials
## We exclude any speakers whose mean performance in control trials is 3 SD above the group mean.
```{r filter out control trials}
data_control <- data_select %>%
  filter(exp == "control") 

control_mean = mean(data_control[, "response_num"])
control_sd = sd(data_control[, "response_num"])
max_control = control_mean + 3 * control_sd

# omit mean response 3 SD above the group mean (per factive paper)
id_omit <- data_control %>%
  group_by(workerid) %>%
  summarise(response_mean_control = mean(response_num)) %>%
  filter(max_control < response_mean_control)
id_omit <- id_omit[, "workerid"]
length(id_omit) # no one removed
View(id_omit)

id_select <- data_control %>%
  group_by(workerid) %>%
  summarise(response_mean_control = mean(response_num)) %>%
  filter(response_mean_control <= max_control)

id_select <- pull(id_select[c("workerid")])
length(id_select) # 144 participants left
```

```{r filter out stimuli trials}
data_stim <- data_select %>% 
  filter(workerid %in% id_select) %>%
  filter(exp == "stim") %>%
  mutate(Word = ifelse(Word == "facinate", "fascinate", as.character(Word))) ## coded "fascinate" wrongly :(

data <- merge(data_stim, top_words_selected, by = "Word")
data$valence_arousal_group = factor(data$valence_arousal_group, levels=c("high negative valence, low arousal", "high negative valence, medium arousal", "high negative valence, high arousal", "low valence, low arousal", "low valence, medium arousal", "low valence, high arousal", "high positive valence, low arousal", "high positive valence, medium arousal", "high positive valence, high arousal")) 

# normalize response_norm by participants
data_norm <- data %>%
  group_by(workerid) %>%
  mutate(response_norm = (response_num - mean(response_num)) / sd(response_num))
```

```{r average by word}
# get participants whose native language is English
data_by_word <- data %>%
  group_by(Word, voice, valence_group, valence_bin, valence_bin_group, arousal_bin, valence_arousal_group, carousal_mean, crelativeValence) %>%
  summarise(response_mean = mean(response_num))

data_by_word_norm <- data_norm %>%
  group_by(Word, voice, valence_group, valence_bin, valence_bin_group, arousal_bin, valence_arousal_group, carousal_mean, crelativeValence) %>%
  summarise(response_mean = mean(response_norm))

```

# Plots
## Unnormalized rating against relative valence

```{r}
ggplot(data = data_by_word, aes(x = crelativeValence, y = response_mean, label = Word)) +
  geom_point(width = .3,height = .025, aes(colour = valence_arousal_group)) +
  geom_text_repel(aes(colour = valence_arousal_group)) +
  geom_smooth(method = 'lm') + 
  labs (x = "relative valence", y = "mean at-issue rating", colour = "predicate group")

ggsave("../graphs/at-issueness_by_valence.pdf")

```

## Unnormalized rating agaist arousal mean
```{r}
ggplot(data = data_by_word, aes(x = carousal_mean, y = response_mean, label = Word)) +
  geom_point(width = .3,height = .025, aes(colour = valence_arousal_group)) +
  geom_text_repel(aes(colour = valence_arousal_group)) +
  geom_smooth(method = 'lm') +   
  labs (x = "mean arousal", y = "mean at-issue rating", colour = "predicate group")

ggsave("../graphs/at-issueness_by_arousal.pdf")
```

```{r, include = FALSE}
scatter3D(data_by_word$crelativeValence, data_by_word$carousal_mean, data_by_word$response_mean, theta = 30, phi = 10,
          xlab = "relative valence",
          ylab ="arousal mean", 
          zlab = "response mean")
```


```{r extra plots, include = FALSE}
# some extra plots
ggplot(data = data_by_word, aes(x = crelativeValence, y = response_mean, colour = valence_group, label = Word)) +
  geom_point(width = .3,height = .025) +
  geom_label() +
  geom_smooth(method = 'lm')

ggplot(data = data_by_word, aes(x = crelativeValence, y = response_mean, colour = valence_group, label = Word)) +
  geom_point(width = .3,height = .025) +
  facet_grid(~voice) +
  geom_label() +
  geom_smooth(method = 'lm')

ggplot(data = data_by_word, aes(x = crelativeValence, y = response_mean, colour = valence_group, label = Word)) +
  geom_point(width = .3,height = .025) +
  facet_grid(~valence_arousal_group) +
  geom_label() +
  geom_smooth(method = 'lm')

#maybe color with gradient? 
#maybe color = arousal, shape = valence? 
ggplot(data = data_by_word, aes(x = carousal_mean, y = response_mean, colour = arousal_bin, label = Word)) +
  geom_point(width = .3,height = .025) +
  geom_label() +
  geom_smooth(method = 'lm')

ggplot(data = data_by_word, aes(x = carousal_mean, y = response_mean, colour = arousal_bin, label = Word)) +
  geom_point(width = .3,height = .025) +
  facet_grid(~voice) +
  geom_label() +
  geom_smooth(method = 'lm')

ggplot(data = data_by_word, aes(x = carousal_mean, y = response_mean, colour = arousal_bin, label = Word)) +
  geom_point(width = .3,height = .025) +
  facet_grid(~valence_arousal_group) +
  geom_label() +
  geom_smooth(method = 'lm')
```

# Mixed effects linear model and ANOVA
```{r mixed effects linear model, include = FALSE, warning = FALSE, echo=FALSE}
data_model <- data

m = lmer(response_num ~ carousal_mean * crelativeValence + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model)
summary(m) # main effects of arousal and relative valence!
plot(fitted(m), residuals(m))

#pdf(file="modelcheck_linear.pdf",height=8,width=9)
#check_model(m)
#dev.off()
```

```{r anova, include = FALSE, warning = FALSE, echo=FALSE}
projectivity.full = lmer(response_num ~ carousal_mean * crelativeValence + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model, REML = FALSE)
projectivity.reduced = lmer(response_num ~ 1 + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model, REML = FALSE)
anova(projectivity.reduced, projectivity.full)


#interaction removed
projectivity.int = lmer(response_num ~ carousal_mean + crelativeValence + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model, REML = FALSE)
anova(projectivity.int, projectivity.full)

#only arousal
projectivity.arousal = lmer(response_num ~ carousal_mean + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model, REML = FALSE)
anova(projectivity.int, projectivity.arousal)

#only valence
projectivity.valence = lmer(response_num ~ crelativeValence + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model, REML = FALSE)
anova(projectivity.int, projectivity.valence)

```

```{r mixed bayes, include = FALSE, echo = FALSE}

# m.bayes = brm(response_num ~ carousal_mean * crelativeValence + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), 
#               data = data_model,
#               chains = 4,
#               cores = 4)
# saveRDS(m.bayes, "bayes.rds")
m.bayes <- readRDS("bayes.rds")
summary(m.bayes) # 0 is in 95% CI for interaction, but not for valence / arousal separately
```


