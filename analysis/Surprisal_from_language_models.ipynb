{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating surprisal from language models\n",
    "Take sentences from CommitmentBank, MegaAttitudes, and stimuli from experiment, mask the attitude predicate, and get predicted probability of occurrence for the target verb. Then, calculate from that the surprisal of the verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This makes the display show more info\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CommitmentBank\n",
    "cb = pd.read_csv(\"../data/CommitmentBank-ALL.csv\")[[\"uID\",\"Verb\",\"Target\"]].drop_duplicates()\n",
    "cb = cb.rename(columns={\"Target\": \"Sentence\",\"uID\":\"ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MegaVeridicality\n",
    "mv = pd.read_csv(\"../data/mega-veridicality-v2.csv\")[[\"verb\",\"frame\",\"voice\",\"sentence\"]].drop_duplicates()\n",
    "mv = mv.rename(columns={\"verb\": \"Verb\", \"sentence\":\"Sentence\"})\n",
    "mv[\"ID\"] = mv[['frame', 'voice']].apply(lambda x: '_'.join(x), axis=1)\n",
    "mv = mv.drop(columns=[\"frame\",\"voice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arousal/Valence Study\n",
    "vs = pd.read_csv(\"../data/1_sliderprojection/exp1_test-trials.csv\")[[\"Word\",\"utterance\",\"exp\"]]\n",
    "vs = vs[vs[\"exp\"]==\"stim\"].drop_duplicates().drop(columns={\"exp\"})\n",
    "vs = vs.rename(columns={\"Word\": \"Verb\",\"utterance\":\"Sentence\"})\n",
    "vs[\"ID\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine them together into one df\n",
    "df = pd.concat([cb,mv,vs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to deal with the inflected verb token \n",
    "1. by creating a new verb token column\n",
    "2. regex with literal string interpolation to match work in which the Verb occurrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"VerbToken\"] = df['Sentence'].str.extract(fr'({df[\"Verb\"]}\\w*)')\n",
    "\n",
    "# Find a match in the Sentence column for the verb from the Verb column using a regex\n",
    "# re.search() returns a match object, so you have to call .group() to get the string\n",
    "# that is matched. In cases where there is no match, a NoneType object is returned and \n",
    "# you can't call .group() on that. \n",
    "df[\"VerbToken\"] = df.apply(lambda x: re.search(fr'({x[\"Verb\"]}\\w*)',x['Sentence']), axis=1)\n",
    "\n",
    "# \n",
    "df[\"VerbToken\"] = df[\"VerbToken\"].apply(lambda x: x.group() if x is not None else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = df[df[\"VerbToken\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.060509554140127"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(empty)/len(df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GET THOSE EMPTIES\n",
    "lemmatize the whole sentence and look for the matches to lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://gaurav5430.medium.com/using-nltk-for-lemmatizing-sentences-c1bfff963258\n",
    "# initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_verb_from_sentence(sentence,verb):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lw = []\n",
    "#     for i in range(0,len(empty)-1):\n",
    "#     for v in empty[\"Verb\"].values:\n",
    "#         verb_from_empty = empty[\"Verb\"].values[i]\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            continue\n",
    "        elif tag != 'v':\n",
    "            continue\n",
    "        else:\n",
    "            lemma = lemmatizer.lemmatize(word, tag)\n",
    "            if lemma != verb:\n",
    "                # Go to the next word/tag pair to find the relevant verb\n",
    "                break\n",
    "            elif lemma == verb:\n",
    "                print(\"{verb}: {word} {lemma}\".format(verb=verb,word=word,lemma=lemma))\n",
    "                lw.append(word)\n",
    "                lw.append(lemma)\n",
    "#     print(lw)\n",
    "    return ' '.join(lw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to be working to break it up more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_verb(sentence):\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "    verbs = []\n",
    "    for i in nltk_tagged:\n",
    "        if 'VB' in i[1]:\n",
    "            verbs.append(i)\n",
    "    return verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = get_verb(\"She could also have told this was Tina's mother before Mrs Darne went off down the passage that led to the Headmaster's Flat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-463aecabe8aa>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  empty[\"VerbList\"] = empty[\"Sentence\"].apply(lambda x: get_verb(x))\n"
     ]
    }
   ],
   "source": [
    "empty[\"VerbList\"] = empty[\"Sentence\"].apply(lambda x: get_verb(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-8b41673c2e32>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  empty[\"VerbTagged\"] = empty[\"Verb\"].apply(lambda x: nltk.pos_tag([x]))\n"
     ]
    }
   ],
   "source": [
    "empty[\"VerbTagged\"] = empty[\"Verb\"].apply(lambda x: nltk.pos_tag([x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_from_nltk_tagged_list(nltk_tagged):\n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-8a1491a9a5a8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  empty[\"VerbListLemmatized\"] = empty[\"VerbList\"].apply(lambda x: lemmatize_from_nltk_tagged_list(x))\n"
     ]
    }
   ],
   "source": [
    "empty[\"VerbListLemmatized\"] = empty[\"VerbList\"].apply(lambda x: lemmatize_from_nltk_tagged_list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>VerbToken</th>\n",
       "      <th>VerbList</th>\n",
       "      <th>VerbTagged</th>\n",
       "      <th>VerbListLemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BNC-1002</td>\n",
       "      <td>say</td>\n",
       "      <td>Indeed it could be said that they had prospered.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(be, VB), (said, VBD), (had, VBD), (prospered, VBN)]</td>\n",
       "      <td>[(say, VB)]</td>\n",
       "      <td>[be, say, have, prosper]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BNC-1003</td>\n",
       "      <td>say</td>\n",
       "      <td>He might have said to her that some time in the middle of the nineteenth century a cult had grown up around the idea of the home.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(have, VB), (said, VBD), (had, VBD), (grown, VBN)]</td>\n",
       "      <td>[(say, VB)]</td>\n",
       "      <td>[have, say, have, grow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>BNC-1145</td>\n",
       "      <td>tell</td>\n",
       "      <td>She could also have told this was Tina's mother before Mrs Darne went off down the passage that led to the Headmaster's Flat.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(have, VB), (told, VBN), (was, VBD), (went, VBD), (led, VBD)]</td>\n",
       "      <td>[(tell, NN)]</td>\n",
       "      <td>[have, tell, be, go, lead]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>BNC-1187</td>\n",
       "      <td>think</td>\n",
       "      <td>They may have thought they were putting it out of its misery - a lifetime beautifying the lorry-route to the A1.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(have, VB), (thought, VBN), (were, VBD), (putting, VBG), (beautifying, VBG)]</td>\n",
       "      <td>[(think, NN)]</td>\n",
       "      <td>[have, think, be, put, beautify]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>BNC-1194</td>\n",
       "      <td>think</td>\n",
       "      <td>Perhaps he thought that her own wishes would hardly be considered in the matter.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(thought, VBD), (be, VB), (considered, VBN)]</td>\n",
       "      <td>[(think, NN)]</td>\n",
       "      <td>[think, be, consider]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID   Verb  \\\n",
       "9    BNC-1002    say   \n",
       "17   BNC-1003    say   \n",
       "575  BNC-1145   tell   \n",
       "716  BNC-1187  think   \n",
       "733  BNC-1194  think   \n",
       "\n",
       "                                                                                                                              Sentence  \\\n",
       "9                                                                                     Indeed it could be said that they had prospered.   \n",
       "17   He might have said to her that some time in the middle of the nineteenth century a cult had grown up around the idea of the home.   \n",
       "575      She could also have told this was Tina's mother before Mrs Darne went off down the passage that led to the Headmaster's Flat.   \n",
       "716                   They may have thought they were putting it out of its misery - a lifetime beautifying the lorry-route to the A1.   \n",
       "733                                                   Perhaps he thought that her own wishes would hardly be considered in the matter.   \n",
       "\n",
       "    VerbToken  \\\n",
       "9        None   \n",
       "17       None   \n",
       "575      None   \n",
       "716      None   \n",
       "733      None   \n",
       "\n",
       "                                                                          VerbList  \\\n",
       "9                            [(be, VB), (said, VBD), (had, VBD), (prospered, VBN)]   \n",
       "17                             [(have, VB), (said, VBD), (had, VBD), (grown, VBN)]   \n",
       "575                 [(have, VB), (told, VBN), (was, VBD), (went, VBD), (led, VBD)]   \n",
       "716  [(have, VB), (thought, VBN), (were, VBD), (putting, VBG), (beautifying, VBG)]   \n",
       "733                                  [(thought, VBD), (be, VB), (considered, VBN)]   \n",
       "\n",
       "        VerbTagged                VerbListLemmatized  \n",
       "9      [(say, VB)]          [be, say, have, prosper]  \n",
       "17     [(say, VB)]           [have, say, have, grow]  \n",
       "575   [(tell, NN)]        [have, tell, be, go, lead]  \n",
       "716  [(think, NN)]  [have, think, be, put, beautify]  \n",
       "733  [(think, NN)]             [think, be, consider]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-714684832097>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  empty[\"VerbListLemmatizedTagged\"] = empty[\"VerbListLemmatized\"].apply(lambda x: nltk.pos_tag(x))\n"
     ]
    }
   ],
   "source": [
    "empty[\"VerbListLemmatizedTagged\"] = empty[\"VerbListLemmatized\"].apply(lambda x: nltk.pos_tag(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>VerbToken</th>\n",
       "      <th>VerbList</th>\n",
       "      <th>VerbTagged</th>\n",
       "      <th>VerbListLemmatized</th>\n",
       "      <th>VerbListLemmatizedTagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BNC-1002</td>\n",
       "      <td>say</td>\n",
       "      <td>Indeed it could be said that they had prospered.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(be, VB), (said, VBD), (had, VBD), (prospered, VBN)]</td>\n",
       "      <td>[(say, VB)]</td>\n",
       "      <td>[be, say, have, prosper]</td>\n",
       "      <td>[(be, VB), (say, VBN), (have, VBP), (prosper, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BNC-1003</td>\n",
       "      <td>say</td>\n",
       "      <td>He might have said to her that some time in the middle of the nineteenth century a cult had grown up around the idea of the home.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(have, VB), (said, VBD), (had, VBD), (grown, VBN)]</td>\n",
       "      <td>[(say, VB)]</td>\n",
       "      <td>[have, say, have, grow]</td>\n",
       "      <td>[(have, VBP), (say, VBN), (have, VBP), (grow, NNS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>BNC-1145</td>\n",
       "      <td>tell</td>\n",
       "      <td>She could also have told this was Tina's mother before Mrs Darne went off down the passage that led to the Headmaster's Flat.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(have, VB), (told, VBN), (was, VBD), (went, VBD), (led, VBD)]</td>\n",
       "      <td>[(tell, NN)]</td>\n",
       "      <td>[have, tell, be, go, lead]</td>\n",
       "      <td>[(have, VB), (tell, NN), (be, VB), (go, VBN), (lead, JJ)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>BNC-1187</td>\n",
       "      <td>think</td>\n",
       "      <td>They may have thought they were putting it out of its misery - a lifetime beautifying the lorry-route to the A1.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(have, VB), (thought, VBN), (were, VBD), (putting, VBG), (beautifying, VBG)]</td>\n",
       "      <td>[(think, NN)]</td>\n",
       "      <td>[have, think, be, put, beautify]</td>\n",
       "      <td>[(have, VB), (think, NN), (be, VB), (put, VBN), (beautify, VB)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>BNC-1194</td>\n",
       "      <td>think</td>\n",
       "      <td>Perhaps he thought that her own wishes would hardly be considered in the matter.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(thought, VBD), (be, VB), (considered, VBN)]</td>\n",
       "      <td>[(think, NN)]</td>\n",
       "      <td>[think, be, consider]</td>\n",
       "      <td>[(think, NN), (be, VB), (consider, JJR)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID   Verb  \\\n",
       "9    BNC-1002    say   \n",
       "17   BNC-1003    say   \n",
       "575  BNC-1145   tell   \n",
       "716  BNC-1187  think   \n",
       "733  BNC-1194  think   \n",
       "\n",
       "                                                                                                                              Sentence  \\\n",
       "9                                                                                     Indeed it could be said that they had prospered.   \n",
       "17   He might have said to her that some time in the middle of the nineteenth century a cult had grown up around the idea of the home.   \n",
       "575      She could also have told this was Tina's mother before Mrs Darne went off down the passage that led to the Headmaster's Flat.   \n",
       "716                   They may have thought they were putting it out of its misery - a lifetime beautifying the lorry-route to the A1.   \n",
       "733                                                   Perhaps he thought that her own wishes would hardly be considered in the matter.   \n",
       "\n",
       "    VerbToken  \\\n",
       "9        None   \n",
       "17       None   \n",
       "575      None   \n",
       "716      None   \n",
       "733      None   \n",
       "\n",
       "                                                                          VerbList  \\\n",
       "9                            [(be, VB), (said, VBD), (had, VBD), (prospered, VBN)]   \n",
       "17                             [(have, VB), (said, VBD), (had, VBD), (grown, VBN)]   \n",
       "575                 [(have, VB), (told, VBN), (was, VBD), (went, VBD), (led, VBD)]   \n",
       "716  [(have, VB), (thought, VBN), (were, VBD), (putting, VBG), (beautifying, VBG)]   \n",
       "733                                  [(thought, VBD), (be, VB), (considered, VBN)]   \n",
       "\n",
       "        VerbTagged                VerbListLemmatized  \\\n",
       "9      [(say, VB)]          [be, say, have, prosper]   \n",
       "17     [(say, VB)]           [have, say, have, grow]   \n",
       "575   [(tell, NN)]        [have, tell, be, go, lead]   \n",
       "716  [(think, NN)]  [have, think, be, put, beautify]   \n",
       "733  [(think, NN)]             [think, be, consider]   \n",
       "\n",
       "                                            VerbListLemmatizedTagged  \n",
       "9                 [(be, VB), (say, VBN), (have, VBP), (prosper, NN)]  \n",
       "17               [(have, VBP), (say, VBN), (have, VBP), (grow, NNS)]  \n",
       "575        [(have, VB), (tell, NN), (be, VB), (go, VBN), (lead, JJ)]  \n",
       "716  [(have, VB), (think, NN), (be, VB), (put, VBN), (beautify, VB)]  \n",
       "733                         [(think, NN), (be, VB), (consider, JJR)]  "
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [[x,y] for x,y in zip(list(empty[\"VerbList\"]),list(empty[\"VerbListLemmatizedTagged\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 'VB'), ('say', 'VBN'), ('have', 'VBP'), ('prosper', 'NN')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('be', 'VB'), ('said', 'VBD'), ('had', 'VBD'), ('prospered', 'VBN')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty[\"Grouped\"].values[2][1][i][1]\n",
    "empty[\"VerbListLemmatizedTagged\"].values[2][1][i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty[\"Grouped2\"] = empty.Grouped[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for x, y in zip(xs, ys):\n",
    "    print x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_two_cols(col1,col2)\n",
    "    for x,y in zip(col1,col2):\n",
    "        l = []\n",
    "\n",
    "        if col1 is in col2.tolist():\n",
    "            l.append(col1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>VerbToken</th>\n",
       "      <th>VerbList</th>\n",
       "      <th>VerbTagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BNC-1002</td>\n",
       "      <td>say</td>\n",
       "      <td>Indeed it could be said that they had prospered.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(be, VB), (said, VBD), (had, VBD), (prospered, VBN)]</td>\n",
       "      <td>[(say, VB)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BNC-1003</td>\n",
       "      <td>say</td>\n",
       "      <td>He might have said to her that some time in the middle of the nineteenth century a cult had grown up around the idea of the home.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(have, VB), (said, VBD), (had, VBD), (grown, VBN)]</td>\n",
       "      <td>[(say, VB)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>BNC-1145</td>\n",
       "      <td>tell</td>\n",
       "      <td>She could also have told this was Tina's mother before Mrs Darne went off down the passage that led to the Headmaster's Flat.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(have, VB), (told, VBN), (was, VBD), (went, VBD), (led, VBD)]</td>\n",
       "      <td>[(tell, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>BNC-1187</td>\n",
       "      <td>think</td>\n",
       "      <td>They may have thought they were putting it out of its misery - a lifetime beautifying the lorry-route to the A1.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(have, VB), (thought, VBN), (were, VBD), (putting, VBG), (beautifying, VBG)]</td>\n",
       "      <td>[(think, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>BNC-1194</td>\n",
       "      <td>think</td>\n",
       "      <td>Perhaps he thought that her own wishes would hardly be considered in the matter.</td>\n",
       "      <td>None</td>\n",
       "      <td>[(thought, VBD), (be, VB), (considered, VBN)]</td>\n",
       "      <td>[(think, NN)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID   Verb  \\\n",
       "9    BNC-1002    say   \n",
       "17   BNC-1003    say   \n",
       "575  BNC-1145   tell   \n",
       "716  BNC-1187  think   \n",
       "733  BNC-1194  think   \n",
       "\n",
       "                                                                                                                              Sentence  \\\n",
       "9                                                                                     Indeed it could be said that they had prospered.   \n",
       "17   He might have said to her that some time in the middle of the nineteenth century a cult had grown up around the idea of the home.   \n",
       "575      She could also have told this was Tina's mother before Mrs Darne went off down the passage that led to the Headmaster's Flat.   \n",
       "716                   They may have thought they were putting it out of its misery - a lifetime beautifying the lorry-route to the A1.   \n",
       "733                                                   Perhaps he thought that her own wishes would hardly be considered in the matter.   \n",
       "\n",
       "    VerbToken  \\\n",
       "9        None   \n",
       "17       None   \n",
       "575      None   \n",
       "716      None   \n",
       "733      None   \n",
       "\n",
       "                                                                          VerbList  \\\n",
       "9                            [(be, VB), (said, VBD), (had, VBD), (prospered, VBN)]   \n",
       "17                             [(have, VB), (said, VBD), (had, VBD), (grown, VBN)]   \n",
       "575                 [(have, VB), (told, VBN), (was, VBD), (went, VBD), (led, VBD)]   \n",
       "716  [(have, VB), (thought, VBN), (were, VBD), (putting, VBG), (beautifying, VBG)]   \n",
       "733                                  [(thought, VBD), (be, VB), (considered, VBN)]   \n",
       "\n",
       "        VerbTagged  \n",
       "9      [(say, VB)]  \n",
       "17     [(say, VB)]  \n",
       "575   [(tell, NN)]  \n",
       "716  [(think, NN)]  \n",
       "733  [(think, NN)]  "
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_verb_from_list(sentence,verb):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lw = []\n",
    "#     for i in range(0,len(empty)-1):\n",
    "#     for v in empty[\"Verb\"].values:\n",
    "#         verb_from_empty = empty[\"Verb\"].values[i]\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            continue\n",
    "        elif tag != 'v':\n",
    "            continue\n",
    "        else:\n",
    "            lemma = lemmatizer.lemmatize(word, tag)\n",
    "            if lemma != verb:\n",
    "                # Go to the next word/tag pair to find the relevant verb\n",
    "                break\n",
    "            elif lemma == verb:\n",
    "                print(\"{verb}: {word} {lemma}\".format(verb=verb,word=word,lemma=lemma))\n",
    "                lw.append(word)\n",
    "                lw.append(lemma)\n",
    "#     print(lw)\n",
    "    return ' '.join(lw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "think: thought think\n",
      "think: thought think\n",
      "think: thought think\n",
      "think: thought think\n",
      "think: thought think\n",
      "say: say say\n",
      "say: said say\n",
      "tell: told tell\n",
      "think: thought think\n",
      "think: thought think\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "think: think think\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "tell: tell tell\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "tell: told tell\n",
      "think: thought think\n",
      "think: thought think\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n",
      "say: said say\n"
     ]
    }
   ],
   "source": [
    "lemma = empty[\"Sentence\"].apply(lambda x: lemmatize_verb_from_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value'] = [x if x > 0 else y if y>0 for x,y in zip(df['a'],df['b'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating surprisal\n",
    "\n",
    "https://twitter.com/bruno_nicenboim/status/1379168059311656963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Masked\"] = df.apply(lambda x: x['Sentence'].replace(x[\"VerbToken\"],\"[MASK]\"),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9       say\\n9       sob\\n9    murmur'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Verb\"][9].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through the CommitmentBank and change the masks by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Verb\n",
       "feel        5\n",
       "find        2\n",
       "foresee     1\n",
       "forget      9\n",
       "hope        1\n",
       "know        9\n",
       "realize     3\n",
       "say        18\n",
       "see         1\n",
       "tell        9\n",
       "think      29\n",
       "Name: Verb, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty.groupby([\"Verb\"])[\"Verb\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Language Modeling\n",
    "using BERT large uncased on a masked task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline('fill-mask', model='bert-large-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0471670962870121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"Dana was [MASK] that Mars has no water.\",targets=\"surprised\")[0]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlm_over_df(input_df):\n",
    "    for row in input_df.itterows():\n",
    "        sentence = f\"{s}\".format(s=input_df[\"sentence\"])\n",
    "        verb = f\"{v}\".format(v=input_df[\"verb\"])\n",
    "        mask_fill = unmasker(sentence, targets=verb)\n",
    "        input_df[\"mlm_score\"] = mask_fill[0]['score']\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
