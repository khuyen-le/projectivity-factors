---
title: "Find Predicates with Residuals Closest to 0"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
library(ggplot2)
library(jsonlite)
library(tidyr)
library(stringr)
library(dplyr)
library(ggthemes)
library(ggrepel)
library(dichromat)
library(lme4)
library(performance)
library(languageR)
library(gghighlight)
theme_set(theme_bw())
```

```{r}
vp_raw <- read.csv("../data/mega-veridicality-v2.csv")
emotion_raw <- read.csv("../data/BRM-emot-submit.csv")
emotion_select <- select(emotion_raw, "Word", "V.Mean.Sum", "V.SD.Sum", "A.Mean.Sum", "A.SD.Sum")
vp_data <- select(vp_raw, "participant", "verb", "frame", "voice", "polarity", "conditional", "sentence", "veridicality", "acceptability", "exclude")
```
#### Norming valence mean to get positive and negative valence
```{r}
emotion <- emotion_select %>%
  mutate(valence_scaled = scale(V.Mean.Sum))
word_list <- unique(emotion$Word)
```

```{r}
# Need to filter by acceptability (see 2019 paper)
# Need to normalize by participants (2016 paper used "ordinal model-based normalization procedure")
vp_data <- vp_data %>%
  mutate(veridicality_num = ifelse(veridicality == "yes", 1, ifelse(veridicality == "no", -1, 0))) %>%
  filter(exclude == "False") %>%
  filter(frame == "that_S") %>%
  mutate(Word = verb) %>%
  filter(Word %in% word_list)
```

#### create relevant subset for projectivity ratings
##### examples of items: 
```{r table_projectivity, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl_proj <- "
| Frame  | Voice  | Valence  | Sentence                                                                          | Note                                    |
|--------|:------:|:--------:|-----------------------------------------------------------------------------------| ----------------------------------------|
| that_S | active | positive | If John didn't find that a particular thing happened, did that thing happen?      | arousal low, projectivity low           |
| that_S | passive| negative | If John wasn't scared that a particular thing happened, did that thing happen?    | arousal high, projectivity high         |
| that_S | active | positive | If John didn't discover that a particular thing happened, did that thing happen?  | outlier: arousal high, projectivity low |
| that_S | passive| positive | If John wasn't jarred that a particular thing happened, did that thing happen?    | outlier: arousal low, projectivity high |
| that_S | active | negative | If John didn't resent that a particular thing happened, did that thing happen?    | outlier: arousal low, projectivity high |
| that_S | passive| negative | If John wasn't tricked that a particular thing happened, did that thing happen?   | outlier: arousal high, projectivity low |
"
cat(tabl_proj)
```

```{r, fig.width = 10, fig.height = 8}
projectivity_filter <- vp_data %>%
  filter(polarity == "negative" & conditional == "True") 
```

```{r explore acceptability}
projectivity_filter <- projectivity_filter %>%
  group_by(participant) %>%
  mutate(acceptability_norm = (acceptability - mean(acceptability)) / sd(acceptability))

# only take acceptability >= 0
projectivity_filter <- projectivity_filter %>%
  filter(acceptability_norm >= 0)
```

```{r merge with emotion}
projectivity_filter <- merge(projectivity_filter, emotion, by = "Word", all.x = TRUE) 
projectivity_filter <- projectivity_filter %>%
  rename(valence_mean = valence_scaled, arousal_mean = A.Mean.Sum, valence_SD = V.SD.Sum, arousal_SD = A.SD.Sum) %>%
  mutate(valence_group = ifelse(valence_mean < 0, "negative", "positive"))
```

#### Sort predicates according to valence
```{r}
projectivity_neg_participant <- projectivity_filter %>%
  filter(valence_group == "negative")

projectivity_neg_participant <-projectivity_neg_participant[order(projectivity_neg_participant$valence_mean),]

valence_mean <- projectivity_neg_participant[, "valence_mean"]
valence_bin <- cut(valence_mean, 3, include.lowest=TRUE, labels=c("very negative", "moderately negative", "slightly negative"))
projectivity_neg_participant <- cbind(projectivity_neg_participant, valence_bin)

projectivity_pos_participant <- projectivity_filter %>%
  filter(valence_group == "positive")

projectivity_pos_participant <-projectivity_pos_participant[order(projectivity_pos_participant$valence_mean),]

valence_mean <- projectivity_pos_participant[, "valence_mean"]
valence_bin <- cut(valence_mean, 3, include.lowest=TRUE, labels=c("slightly positive", "moderately positive", "very positive"))
projectivity_pos_participant <- cbind(projectivity_pos_participant, valence_bin)

projectivity_participant <- rbind(projectivity_neg_participant, projectivity_pos_participant)

projectivity_participant <- projectivity_participant %>%
  mutate(valence_bin_group = ifelse((valence_bin == "very positive" | valence_bin == "moderately positive"), "high positive", (ifelse((valence_bin == "very negative" | valence_bin == "moderately negative"),  "high negative", "low"))))

# ggplot(data = projectivity_participant, aes(x = valence_mean, y = projectivity_mean, colour = valence_group, label = Word)) +
#   #geom_point(width = .3,height = .025) +
#   geom_label() +
#   geom_smooth(method = 'lm')
# 
# ggplot(data = projectivity_participant, aes(x = arousal_mean, y = projectivity_mean, colour = valence_group, label = Word)) +
#   #geom_point(width = .3,height = .025) + 
#   facet_grid(~valence_group) +
#   geom_label() +
#   geom_smooth(method = 'lm')
# 
# # taking into account voice
# ggplot(data = projectivity_participant, aes(x = arousal_mean, y = projectivity_mean, colour = valence_group, label = Word)) +
#   #geom_point(width = .3,height = .025) + 
#   facet_grid(voice~valence_group) +
#   geom_label() +rm 
#   geom_smooth(method = 'lm')
```

#### Sort predicates by arousal
```{r}
projectivity_participant <- projectivity_participant[order(projectivity_participant$arousal_mean),]

arousal_mean <- projectivity_participant[, "arousal_mean"]
arousal_bin <- cut(arousal_mean, 3, include.lowest=TRUE, labels=c("low", "medium", "high"))
projectivity_participant <- cbind(projectivity_participant, arousal_bin)

```

```{r plot projectivity by valence and arousal}
projectivity_summarize <- projectivity_participant %>%
  group_by(Word, valence_mean, valence_group, valence_bin, arousal_mean, arousal_bin) %>%
  summarise(projectivity_mean = mean(veridicality_num))
  
ggplot(data = projectivity_summarize, aes(x = arousal_mean, y = projectivity_mean, colour = arousal_bin, label = Word)) +
  #geom_point(width = .3,height = .025) +
  geom_label() +
  geom_smooth(method = 'lm')

ggplot(data = projectivity_summarize, aes(x = valence_mean, y = projectivity_mean,, colour = valence_bin, label = Word)) +
  #geom_point(width = .3,height = .025) +
  geom_label() +
  geom_smooth(method = 'lm')
```

```{r mixed effects linear model}
# visualize correlations between variables
#pairscor.fnc(projectivity_participant[,c("veridicality_num","arousal_mean","relativeValence","valence_mean")])

# the model check of the model as previously formulated (ie, with uncentered predictors) suggested huge collinearity, almost all values in covariance matrix > .4). the current model check still suggests there's sth wonky going on with the homoscedasticity tests (because the outcome variable is a three-way categorical variable instead of continuous, which we can't do anything about within the model, but see logistic model below that replicates the result). 
projectivity_participant$relativeValence = abs(projectivity_participant$valence_mean)
projectivity_participant = projectivity_participant %>%
  mutate(crelativeValence=relativeValence-mean(relativeValence),
        carousal_mean=arousal_mean-mean(arousal_mean))

m = lmer(veridicality_num ~ carousal_mean * crelativeValence + (1 | participant) + (1 | Word), data = projectivity_participant)
summary(m) # main effects of arousal and relative valence!
plot(fitted(m), residuals(m))

pdf(file="modelcheck_linear.pdf",height=8,width=9)
check_model(m)
dev.off()

factivity.full = lmer(veridicality_num ~ carousal_mean * crelativeValence + (1 | participant) + (1 | Word), data = projectivity_participant, REML = FALSE)
factivity.reduced = lmer(veridicality_num ~ 1 + (1 | participant) + (1 | Word), data = projectivity_participant, REML = FALSE)
anova(factivity.reduced, factivity.full)

```
#### Sort residuals
```{r}
### Residuals might be different within the same predicates because veridicality_num of each participant is different
### Thus, not using unique predicates (not sure if this is a problem)
projectivity_participant$residuals <- residuals(m)
projectivity_participant$residuals_abs <- abs(projectivity_participant$residuals)
projectivity_participant_summary <- projectivity_participant %>%
  group_by(Word, voice, frame, sentence, valence_group, valence_bin, valence_bin_group, arousal_bin, carousal_mean, crelativeValence, valence_mean) %>%
  summarize(mean_residuals_abs = mean(residuals_abs), mean_acceptability_norm = mean(acceptability_norm, na.rm = TRUE), projectivity_mean = mean(veridicality_num)) ## mean_acceptability_norm for display only
projectivity_participant_summary <- projectivity_participant_summary[order(projectivity_participant_summary$mean_residuals_abs),]

valence_highpos_arousal_high <- projectivity_participant_summary %>%
  filter(valence_bin_group == "high positive" & arousal_bin == "high")
valence_highpos_arousal_med <- projectivity_participant_summary %>%
  filter(valence_bin_group == "high positive" & arousal_bin == "medium")
valence_highpos_arousal_low <- projectivity_participant_summary %>%
  filter(valence_bin_group == "high positive" & arousal_bin == "low")
valence_highneg_arousal_high <- projectivity_participant_summary %>%
  filter(valence_bin_group == "high negative" & arousal_bin == "high")
valence_highneg_arousal_med <- projectivity_participant_summary %>%
  filter(valence_bin_group == "high negative" & arousal_bin == "medium")
valence_highneg_arousal_low <- projectivity_participant_summary %>%
  filter(valence_bin_group == "high negative" & arousal_bin == "low")
valence_low_arousal_high <- projectivity_participant_summary %>%
  filter(valence_bin_group == "low" & arousal_bin == "high")
valence_low_arousal_med <- projectivity_participant_summary %>%
  filter(valence_bin_group == "low" & arousal_bin == "medium")
valence_low_arousal_low <- projectivity_participant_summary %>%
  filter(valence_bin_group == "low" & arousal_bin == "low")

valence_highpos_arousal_low_by_relativevalence <- valence_highpos_arousal_low[order(valence_highpos_arousal_low$crelativeValence), ]

projectivity_participant_summary <- projectivity_participant_summary %>%
  mutate(valence_arousal_group = ifelse(valence_bin_group == "high positive" & arousal_bin == "high", "high positive valence, high arousal", ifelse(valence_bin_group == "high positive" & arousal_bin == "medium", "high positive valence, medium arousal", ifelse(valence_bin_group == "high positive" & arousal_bin == "low", "high positive valence, low arousal", ifelse (valence_bin_group == "high negative" & arousal_bin == "high", "high negative valence, high arousal", ifelse(valence_bin_group == "high negative" & arousal_bin == "medium", "high negative valence, medium arousal", ifelse(valence_bin_group == "high negative" & arousal_bin == "low", "high negative valence, low arousal", ifelse(valence_bin_group == "low" & arousal_bin == "high", "low valence, high arousal", ifelse (valence_bin_group == "low" & arousal_bin == "medium", "low valence, medium arousal", "low valence, low arousal")))))))))

top_words <- rbind(arrange(valence_highpos_arousal_high[1:10, ], desc(mean_acceptability_norm)),
                   arrange(valence_highpos_arousal_med[1:10, ], desc(mean_acceptability_norm)),
                   arrange(valence_highpos_arousal_low[1:10, ], desc(mean_acceptability_norm)),
                   arrange(valence_highneg_arousal_high[1:10, ], desc(mean_acceptability_norm)), 
                   arrange(valence_highneg_arousal_med[1:10, ], desc(mean_acceptability_norm)),
                   arrange(valence_highneg_arousal_low[1:10, ], desc(mean_acceptability_norm)),
                   arrange(valence_low_arousal_high[1:10, ], desc(mean_acceptability_norm)),
                   arrange(valence_low_arousal_med[1:10, ], desc(mean_acceptability_norm)),
                   arrange(valence_low_arousal_low[1:10, ], desc(mean_acceptability_norm)))
top_words_10 <- na.omit(top_words) # some categories have fewer than 10 words)
top_words$Word
#write.csv(top_words_10, "top_words_10.csv")
#kable(top_words)
#word_list <- top_words$Word
#write.csv(top_words_7, "top_words_7.csv")
#write.csv(top_words_by_bins, "top_words_by_bins.csv")
```

```{r}
top_words_selected <- projectivity_participant_summary %>%
  filter((Worsd %in% c("amuse", "enjoy", "elaborate", "charm", "fantasize", "love")) |
         (Word %in% c("think", "feel", "pray", "envision", "write") | (Word %in% c("promise") & voice == "passive")) |
         (Word %in% c("irritate", "cringe", "scream", "aggravate", "argue", "pain")) |
         (Word %in% c("embarrass", "offend", "trouble", "torture", "insult", "disgust")) |
         (Word %in% c("weep", "distress", "resent", "ignore", "gossip", "whine")) |
         (Word %in% c("shock", "anticipate", "alarm", "expose", "shout", "testify")) |
         (Word %in% c("verify", "simulate", "squeal", "express", "require") | (Word %in% c("bet") & voice == "active")) |
         (Word %in% c("murmur", "suppose", "retract", "dictate", "compute") | (Word %in% c("tweet") & voice == "active")) | 
         (Word %in% c("surprise", "thrill", "excite", "joke", "fascinate", "celebrate")) |
         (Word %in% c("discover", "know", "annoy", "see", "realize")))

label_words <- pull(top_words_selected[c("Word")])

projectivity_participant_summary <- projectivity_participant_summary %>%
  mutate(highlight_word = ifelse(Word %in% label_words, 1, 0))
  
summary_data <- as.data.frame(projectivity_participant_summary)

ggplot(data = summary_data, aes(x = valence_mean, y = carousal_mean, label = Word)) +
   geom_point(alpha = 0.1) +
   geom_point(data = top_words_selected, aes(x = valence_mean, y = carousal_mean, colour = valence_arousal_group, label = Word)) +
   geom_text(data = top_words_selected, aes(label=Word),hjust=0, vjust=0)
   #geom_label_repel()

ggplot(data = projectivity_participant_summary, aes(x = crelativeValence, y = carousal_mean, label = Word)) +
  geom_point() +
  gghighlight(highlight_word == 1, label_key = Word) +
  geom_label_repel()

ggplot(data = projectivity_participant_summary, aes(x = carousal_mean, y = crelativeValence, label = Word)) +
  geom_point() +
  gghighlight(highlight_word == 1, label_key = Word) +
  geom_label_repel()

```


```{r, fig.width = 8, fig.height = 8}
label_words <- pull(top_words[c("Word")])

projectivity_participant_summary <- projectivity_participant_summary %>%
  mutate(word_flag = ifelse(Word %in% label_words, 1, 0))
  
ggplot(data = projectivity_participant_summary, aes(x = crelativeValence, y = projectivity_mean, label = Word)) +
  geom_point() +
  gghighlight(word_flag == 1, label_key = Word) +
  facet_grid(~arousal_bin) +
  geom_label_repel() +
  geom_smooth(method = 'lm')




ggplot(data = projectivity_participant_summary, aes(x = carousal_mean, y = projectivity_mean, label = Word)) +
  geom_point() +
  gghighlight(word_flag == 1, label_key = Word) +
  facet_grid(~valence_bin) +
  geom_label_repel() +
  geom_smooth(method = 'lm')
```


```{r mixed effects logistic model}
# create a categorical projectivity variable that treats only "yes" responses as projective, all others as not projective
projectivity_participant$categorical_projectivity = as.factor(ifelse(projectivity_participant$veridicality_num == 1, "projective","non-projective"))

# almost three times as many non-projective compared to projective responses
table(projectivity_participant$categorical_projectivity)
prop.table(table(projectivity_participant$categorical_projectivity))

m = glmer(categorical_projectivity ~ carousal_mean * crelativeValence + (1 | participant) + (1 | Word), data = projectivity_participant, family="binomial")
summary(m) # main effects of arousal and relative valence!

```