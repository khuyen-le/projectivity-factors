---
title: "exp3_at-issue_analysis"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
library(ggplot2)
library(jsonlite)
library(tidyr)
library(stringr)
library(dplyr)
library(ggthemes)
library(ggrepel)
library(dichromat)
library(lme4)
library(lmerTest)
library(performance)
library(languageR)
library(gghighlight)
theme_set(theme_bw())
library(brms)
library(rstan)
library(plot3D)
source("../../../helpers.R")
```

```{r import data}
top_words_selected <- read.csv("../../../explore/top_words_selected.csv")
top_words_selected <- select(top_words_selected, "Word", "voice", "valence_group", "valence_bin", "valence_bin_group", "arousal_bin", "valence_arousal_group", "carousal_mean", "crelativeValence", "valence_mean", "mean_residuals_abs","mean_acceptability_norm")
data_raw <- read.csv("../data/atissue_exp-trials.csv")
data_participants_raw <- read.csv("../data/atissue_exp-subject_information.csv")
```

# Native speakers
## We exclude any speakers who did not report English as a native language in the post-survey demographic questions.
```{r filter native English speakers, warning = FALSE}
# get participants whose native language is English
data_participants <- data_participants_raw %>%
  mutate(language = tolower(language))

nrow(data_participants_raw) #150

#filter out participants who did not report English as native language (n=6)
data_participants = filter(data_participants, grepl("eng", language))
nrow(data_participants) # 144

worker_id <- data_participants$workerid

data_select <- data_raw %>%
  filter(utterance != "bot_check") %>%
  filter(workerid %in% worker_id)

data_select <- data_select %>%
  mutate(response_num = as.numeric(response))
  #mutate(response_num = as.numeric(levels(response))[response])
```
# Control trials
## We exclude any speakers whose mean performance in control trials is 3 SD above the group mean.
```{r filter out control trials}
data_control <- data_select %>%
  filter(exp == "control") 

control_mean = mean(data_control[, "response_num"])
control_sd = sd(data_control[, "response_num"])
max_control = control_mean + 3 * control_sd

# omit mean response 3 SD above the group mean (per factive paper)
id_omit <- data_control %>%
  group_by(workerid) %>%
  summarise(response_mean_control = mean(response_num)) %>%
  filter(max_control < response_mean_control)
id_omit <- id_omit[, "workerid"]
length(id_omit) # no one removed

id_select <- data_control %>%
  group_by(workerid) %>%
  summarise(response_mean_control = mean(response_num)) %>%
  filter(response_mean_control <= max_control)

id_select <- pull(id_select[c("workerid")])
length(id_select) # 144 participants left
```

```{r filter out stimuli trials}
data_stim <- data_select %>% 
  filter(workerid %in% id_select) %>%
  filter(exp == "stim") %>%
  mutate(Word = ifelse(Word == "facinate", "fascinate", as.character(Word))) ## coded "fascinate" wrongly :(

data <- merge(data_stim, top_words_selected, by = "Word")

data$valence_arousal_group = factor(data$valence_arousal_group, levels=c("high negative valence, low arousal", "high negative valence, medium arousal", "high negative valence, high arousal", "low valence, low arousal", "low valence, medium arousal", "low valence, high arousal", "high positive valence, low arousal", "high positive valence, medium arousal", "high positive valence, high arousal")) 

# normalize response_norm by participants
data_norm <- data %>%
  group_by(workerid) %>%
  mutate(response_norm = (response_num - mean(response_num)) / sd(response_num))
```

# center the at-issue response to use as a predictor in projection exp
```{r center at-issueness measure, aggregate and save to .csv to analyse effect of at-issueness on projectivity}

data <- data %>%
  mutate(catissueResponse = response_num-mean(response_num))
# by predicate 
data_by_pred = data %>%
    group_by(Word) %>%
    summarise(cresponse_mean_pred = mean(catissueResponse))
nrow(data_by_pred) #1673???
View(data_by_pred)

# table(data_by_item$Word,data_by_item$content)
write_csv(data_by_pred,"../../../../data/atissue_data-bypred.csv")
```

```{r average by word}
# get participants whose native language is English

data_by_word <- data %>%
  group_by(Word, voice, valence_group, valence_bin, valence_bin_group, arousal_bin, valence_arousal_group, carousal_mean, crelativeValence) %>%
  summarise(response_mean = mean(response_num))

data_by_word_norm <- data_norm %>%
  group_by(Word, voice, valence_group, valence_bin, valence_bin_group, arousal_bin, valence_arousal_group, carousal_mean, crelativeValence) %>%
  summarise(response_mean = mean(response_norm))

```

# Plots
## Unnormalized rating against relative valence

```{r}
ggplot(data = data_by_word, aes(x = crelativeValence, y = response_mean, label = Word)) +
  geom_point(width = .3,height = .025, aes(colour = valence_arousal_group)) +
  geom_text_repel(aes(colour = valence_arousal_group)) +
  geom_smooth(method = 'lm') + 
  labs (x = "relative valence", y = "mean at-issue rating", colour = "predicate group")

ggsave("../graphs/at-issueness_by_valence.pdf")

```

## Unnormalized rating agaist arousal mean
```{r}
ggplot(data = data_by_word, aes(x = carousal_mean, y = response_mean, label = Word)) +
  geom_point(width = .3,height = .025, aes(colour = valence_arousal_group)) +
  geom_text_repel(aes(colour = valence_arousal_group)) +
  geom_smooth(method = 'lm') +   
  labs (x = "mean arousal", y = "mean at-issue rating", colour = "predicate group")

ggsave("../graphs/at-issueness_by_arousal.pdf")
```

```{r, include = FALSE}
scatter3D(data_by_word$crelativeValence, data_by_word$carousal_mean, data_by_word$response_mean, theta = 30, phi = 10,
          xlab = "relative valence",
          ylab ="arousal mean", 
          zlab = "response mean")
```


```{r extra plots, include = FALSE}
# some extra plots
ggplot(data = data_by_word, aes(x = crelativeValence, y = response_mean, colour = valence_group, label = Word)) +
  geom_point(width = .3,height = .025) +
  geom_label() +
  geom_smooth(method = 'lm')

ggplot(data = data_by_word, aes(x = crelativeValence, y = response_mean, colour = valence_group, label = Word)) +
  geom_point(width = .3,height = .025) +
  facet_grid(~voice) +
  geom_label() +
  geom_smooth(method = 'lm')

ggplot(data = data_by_word, aes(x = crelativeValence, y = response_mean, colour = valence_group, label = Word)) +
  geom_point(width = .3,height = .025) +
  facet_grid(~valence_arousal_group) +
  geom_label() +
  geom_smooth(method = 'lm')

#maybe color with gradient? 
#maybe color = arousal, shape = valence? 
ggplot(data = data_by_word, aes(x = carousal_mean, y = response_mean, colour = arousal_bin, label = Word)) +
  geom_point(width = .3,height = .025) +
  geom_label() +
  geom_smooth(method = 'lm')

ggplot(data = data_by_word, aes(x = carousal_mean, y = response_mean, colour = arousal_bin, label = Word)) +
  geom_point(width = .3,height = .025) +
  facet_grid(~voice) +
  geom_label() +
  geom_smooth(method = 'lm')

ggplot(data = data_by_word, aes(x = carousal_mean, y = response_mean, colour = arousal_bin, label = Word)) +
  geom_point(width = .3,height = .025) +
  facet_grid(~valence_arousal_group) +
  geom_label() +
  geom_smooth(method = 'lm')
```
 


# Mixed effects linear model and ANOVA 
```{r mixed effects linear model, include = FALSE, warning = FALSE, echo=FALSE}
data_model <- data

m = lmer(response_num ~ carousal_mean * crelativeValence + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model)
summary(m) # main effects of arousal and relative valence!
plot(fitted(m), residuals(m))

#pdf(file="modelcheck_linear.pdf",height=8,width=9)
#check_model(m)
#dev.off()
```

```{r anova, include = FALSE, warning = FALSE, echo=FALSE}
atissueness.full = lmer(response_num ~ carousal_mean * crelativeValence + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model, REML = FALSE)
atissueness.reduced = lmer(response_num ~ 1 + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model, REML = FALSE)
anova(atissueness.reduced, atissueness.full)


#interaction removed
atissueness.int = lmer(response_num ~ carousal_mean + crelativeValence + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model, REML = FALSE)
anova(atissueness.int, atissueness.full)

#only arousal
atissueness.arousal = lmer(response_num ~ carousal_mean + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model, REML = FALSE)
anova(atissueness.int, atissueness.arousal)

#only valence
atissueness.valence = lmer(response_num ~ crelativeValence + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), data = data_model, REML = FALSE)
anova(atissueness.int, atissueness.valence)

```

```{r mixed bayes, include = FALSE, echo = FALSE}

# m.bayes = brm(response_num ~ carousal_mean * crelativeValence + (1 + (carousal_mean * crelativeValence) | workerid) + (1 | Word) + (1 + (carousal_mean * crelativeValence) | content), 
#               data = data_model,
#               chains = 4,
#               cores = 4)
# saveRDS(m.bayes, "bayes.rds")
m.bayes <- readRDS("bayes.rds")
summary(m.bayes) # 0 is in 95% CI for interaction, but not for valence / arousal separately
```


